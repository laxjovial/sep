import logging
import io
import uuid
import sys
import contextlib
import traceback
import json # For handling JSON data from historical tools
from typing import Dict, Any, Optional, List # Import List for type hinting

from langchain_core.tools import tool

# Import user_manager for RBAC checks
from utils.user_manager import get_user_tier_capability

# Import UserProfile for type hinting
from backend.models.user_models import UserProfile

logger = logging.getLogger(__name__)

# Make python_interpreter_with_rbac a standalone async function,
# accepting chart_tools and export_dataframe_to_file_func as arguments.
@tool
async def python_interpreter_with_rbac(
    code: str,
    user_context: UserProfile,
    chart_tools: Any, # Dependency injected
    export_dataframe_to_file_func: Any # Dependency injected
) -> str:
    """
    Executes Python code in a sandboxed environment and captures its output.
    This tool is intended for data analysis, calculations, and other programmatic tasks.
    Access to this tool is controlled by Role-Based Access Control (RBAC).
    The Python code executed by this tool is generated by the LLM based on user queries,
    not directly provided by the end-user.

    Args:
        code (str): The Python code to execute.
        user_context (UserProfile): The user's profile for RBAC checks.
        chart_tools (Any): An instance of ChartTools to be used within the interpreted code.
        export_dataframe_to_file_func (Any): The function for exporting dataframes.

    Returns:
        str: The captured standard output (stdout) and standard error (stderr) of the executed code.
             Returns an error message if execution fails or if access is denied by RBAC.
    """
    user_id = user_context.user_id
    logger.info(f"Tool: python_interpreter_with_rbac called by user: {user_id}. Code (first 100 chars): '{code[:100]}...'")

    # RBAC Check for Data Analysis Enabled
    if not get_user_tier_capability(user_id, 'data_analysis_enabled', False, user_tier=user_context.tier, user_roles=user_context.roles):
        # Enticement message
        return (
            "Error: Python interpreter (data analysis) is not enabled for your current tier. "
            "Upgrade to a Pro or Premium plan to unlock powerful data analysis capabilities!"
        )

    # Use a string buffer to capture stdout and stderr
    old_stdout = sys.stdout
    old_stderr = sys.stderr
    redirected_output = io.StringIO()
    
    sys.stdout = redirected_output
    sys.stderr = redirected_output

    try:
        # Create a restricted global and local namespace for execution
        exec_globals = {}
        exec_locals = {}

        # Add common data analysis libraries to the execution context for convenience
        try:
            import pandas as pd
            exec_globals['pd'] = pd
        except ImportError:
            logger.warning("Pandas not available for Python interpreter.")
        
        try:
            import numpy as np
            exec_globals['np'] = np
        except ImportError:
            logger.warning("NumPy not available for Python interpreter.")

        # Inject other tools/functions into the execution environment
        # These are now passed as arguments to the function
        exec_globals['chart_tools'] = chart_tools
        exec_globals['export_data_to_file'] = export_dataframe_to_file_func
        exec_globals['user_context'] = user_context # Pass user_context for tools that need it

        # Execute the code
        exec(code, exec_globals, exec_locals)
        
        output = redirected_output.getvalue()
        logger.info(f"Python interpreter executed successfully for user {user_id}. Output: {output[:200]}...")
        return f"Execution successful. Output:\n{output}"

    except Exception as e:
        # Capture traceback for more detailed error messages
        error_output = redirected_output.getvalue()
        full_traceback = traceback.format_exc()
        logger.error(f"Python interpreter execution failed for user {user_id}: {e}\nOutput: {error_output}\nTraceback: {full_traceback}", exc_info=True)
        return f"Execution failed. Error:\n{error_output}\n{full_traceback}"
    finally:
        # Restore original stdout and stderr
        sys.stdout = old_stdout
        sys.stderr = old_stderr

# CLI Test (optional)
if __name__ == "__main__":
    import asyncio
    import sys
    from unittest.mock import MagicMock, AsyncMock, patch
    import shutil # For cleaning up chart directories
    from pathlib import Path

    # Mock UserProfile for testing
    from backend.models.user_models import UserProfile
    mock_user_pro_profile = UserProfile(user_id="mock_pro_token", username="ProUser", email="pro@example.com", tier="pro", roles=["user"])
    mock_user_premium_profile = UserProfile(user_id="mock_premium_token", username="PremiumUser", email="premium@example.com", tier="premium", roles=["user"])
    mock_user_free_profile = UserProfile(user_id="mock_free_token", username="FreeUser", email="free@example.com", tier="free", roles=["user"])
    mock_user_admin_profile = UserProfile(user_id="mock_admin_token", username="AdminUser", email="admin@example.com", tier="admin", roles=["user", "admin"])

    # Mock ChartTools and export_utils functions
    # You will need to ensure ChartTools and export_dataframe_to_file exist elsewhere
    # For this test, we'll use a local mock class for ChartTools
    class MockChartTools:
        def __init__(self):
            pass
        async def generate_and_save_chart(self, data_json: str, chart_type: str, x_column: Optional[str] = None, y_column: Optional[str] = None, color_column: Optional[str] = None, title: str = "Generated Chart", x_label: Optional[str] = None, y_label: Optional[str] = None, user_context: UserProfile = None, library: str = "matplotlib", export_format: str = "png", **kwargs: Any) -> str:
            # Simulate chart file creation
            chart_dir = Path("charts") / user_context.user_id
            chart_dir.mkdir(parents=True, exist_ok=True)
            temp_chart_path = chart_dir / f"mock_chart_{uuid.uuid4().hex}.{export_format}"
            with open(temp_chart_path, "w") as f:
                f.write(f"Mock {chart_type} chart content for {title}")
            return str(temp_chart_path)

    async def mock_export_dataframe_to_file(data_json: str, user_context: UserProfile, file_prefix: str = "data_export", export_format: str = "csv") -> str:
        export_dir = Path("exports") / user_context.user_id
        export_dir.mkdir(parents=True, exist_ok=True)
        temp_export_path = export_dir / f"mock_data_{uuid.uuid4().hex}.{export_format}"
        with open(temp_export_path, "w") as f:
            f.write(f"Mock {export_format} data content")
        return str(temp_export_path)

    # Instantiate mocks
    mock_chart_tools_instance = MockChartTools()
    mock_export_dataframe_to_file_func = mock_export_dataframe_to_file

    # Mock user_manager.get_user_tier_capability for testing RBAC
    class MockSecrets:
        # Define any secrets your tests might implicitly need if Streamlit is mocked
        pass

    import streamlit as st_mock
    if not hasattr(st_mock, 'secrets'):
        st_mock.secrets = MagicMock(spec=MockSecrets()) # Use MagicMock for secrets

    class MockUserManager:
        _mock_users = {
            "mock_free_token": {"user_id": "mock_free_token", "username": "FreeUser", "email": "free@example.com", "tier": "free", "roles": ["user"]},
            "mock_pro_token": {"user_id": "mock_pro_token", "username": "ProUser", "email": "pro@example.com", "tier": "pro", "roles": ["user"]},
            "mock_premium_token": {"user_id": "mock_premium_token", "username": "PremiumUser", "email": "premium@example.com", "tier": "premium", "roles": ["user"]},
            "mock_admin_token": {"user_id": "mock_admin_token", "username": "AdminUser", "email": "admin@example.com", "tier": "admin", "roles": ["user", "admin"]},
        }
        _rbac_capabilities = {
            'capabilities': {
                'data_analysis_enabled': {
                    'default': False,
                    'roles': {'pro': True, 'premium': True, 'admin': True}
                },
                'chart_generation_enabled': { # Needed for mock_chart_tools_instance to return success
                    'default': False,
                    'roles': {'pro': True, 'premium': True, 'admin': True}
                },
                'chart_library_access': { # Needed for mock_chart_tools_instance to return success
                    'default': {'matplotlib': True},
                    'tiers': {
                        'pro': {'matplotlib': True, 'seaborn': False, 'plotly': False},
                        'premium': {'matplotlib': True, 'seaborn': True, 'plotly': True},
                        'admin': {'matplotlib': True, 'seaborn': True, 'plotly': True}
                    }
                },
                'chart_type_access': { # Needed for mock_chart_tools_instance to return success
                    'default': {'line': True, 'bar': True, 'scatter': True},
                    'tiers': {
                        'pro': {'line': True, 'bar': True, 'scatter': True, 'histogram': True, 'boxplot': True},
                        'premium': {'line': True, 'bar': True, 'scatter': True, 'histogram': True, 'boxplot': True, 'pie': True, 'area': True},
                        'admin': {'line': True, 'bar': True, 'scatter': True, 'histogram': True, 'boxplot': True, 'pie': True, 'area': True}
                    }
                },
                'chart_export_enabled': { # Needed for mock_chart_tools_instance to return success
                    'default': False,
                    'roles': {'premium': True, 'admin': True}
                }
            }
        }
        _tier_hierarchy = {
            "free": 0, "user": 1, "basic": 2, "pro": 3, "premium": 4, "admin": 99
        }

        def get_user_tier_capability(self, user_id: str, capability_key: str, default_value: Any = None, user_tier: Optional[str] = None, user_roles: Optional[List[str]] = None) -> Any:
            if user_tier is None or user_roles is None:
                user_info = self._mock_users.get(user_id, {})
                user_tier = user_info.get('tier', 'free')
                user_roles = user_info.get('roles', [])

            if "admin" in user_roles:
                if capability_key == 'chart_library_access': return {'matplotlib': True, 'seaborn': True, 'plotly': True}
                if capability_key == 'chart_type_access': return {'line': True, 'bar': True, 'scatter': True, 'histogram': True, 'boxplot': True, 'pie': True, 'area': True}
                if isinstance(default_value, bool): return True
                if isinstance(default_value, (int, float)): return float('inf')
                return default_value
            
            capability_config = self._rbac_capabilities.get('capabilities', {}).get(capability_key)
            if not capability_config:
                return default_value

            for role in user_roles:
                if role in capability_config.get('roles', {}):
                    return capability_config['roles'][role]
            
            if user_tier in capability_config.get('tiers', {}):
                return capability_config['tiers'][user_tier]

            return capability_config.get('default', default_value)

    # Patch the actual imports for testing
    # Patch get_user_tier_capability directly in utils.user_manager
    with patch('utils.user_manager.get_user_tier_capability', new=MockUserManager().get_user_tier_capability):
        # Ensure the patched version is used by the tool
        sys.modules['utils.user_manager'].get_user_tier_capability = MockUserManager().get_user_tier_capability

        # Clean up directories from previous runs
        if Path("charts").exists():
            shutil.rmtree("charts")
        if Path("exports").exists():
            shutil.rmtree("exports")
        Path("charts").mkdir(exist_ok=True)
        Path("exports").mkdir(exist_ok=True)


        async def run_interpreter_tests():
            print("\n--- Testing PythonInterpreterTools functions ---")

            # Test 1: Pro user, simple calculation
            print("\n--- Test 1: Pro user, simple calculation ---")
            code1 = "print(10 + 20)"
            # Pass the mock dependencies to the function
            result1 = await python_interpreter_with_rbac(code1, user_context=mock_user_pro_profile, 
                                                         chart_tools=mock_chart_tools_instance, 
                                                         export_dataframe_to_file_func=mock_export_dataframe_to_file_func)
            print(f"Result 1 (Pro user, calculation): {result1}")
            assert "Execution successful. Output:\n30" in result1
            print("Test 1 Passed.")

            # Test 2: Pro user, pandas usage (mocked)
            print("\n--- Test 2: Pro user, pandas usage (mocked) ---")
            code2 = """
import pandas as pd
data = {'col1': [1, 2], 'col2': [3, 4]}
df = pd.DataFrame(data)
print(df.sum().sum())
"""
            # Mock pandas for this test
            with patch('pandas.DataFrame') as MockDataFrame:
                MockDataFrame.return_value.sum.return_value.sum.return_value = 10 # Mock sum of sums
                result2 = await python_interpreter_with_rbac(code2, user_context=mock_user_pro_profile,
                                                             chart_tools=mock_chart_tools_instance, 
                                                             export_dataframe_to_file_func=mock_export_dataframe_to_file_func)
                print(f"Result 2 (Pro user, pandas): {result2}")
                assert "Execution successful. Output:\n10" in result2
            print("Test 2 Passed.")

            # Test 3: Free user, access denied (with enticement)
            print("\n--- Test 3: Free user, access denied ---")
            code3 = "print('This should not run')"
            result3 = await python_interpreter_with_rbac(code3, user_context=mock_user_free_profile,
                                                         chart_tools=mock_chart_tools_instance, 
                                                         export_dataframe_to_file_func=mock_export_dataframe_to_file_func)
            print(f"Result 3 (Free user): {result3}")
            assert "Error: Python interpreter (data analysis) is not enabled for your current tier." in result3
            assert "Upgrade to a Pro or Premium plan to unlock powerful data analysis capabilities!" in result3
            print("Test 3 Passed.")

            # Test 4: Admin user, code with error
            print("\n--- Test 4: Admin user, code with error ---")
            code4 = "print(1 / 0)" # Division by zero error
            result4 = await python_interpreter_with_rbac(code4, user_context=mock_user_admin_profile,
                                                         chart_tools=mock_chart_tools_instance, 
                                                         export_dataframe_to_file_func=mock_export_dataframe_to_file_func)
            print(f"Result 4 (Admin user, error):\n{result4[:200]}...")
            assert "Execution failed. Error:" in result4
            assert "ZeroDivisionError: division by zero" in result4
            print("Test 4 Passed.")

            # Test 5: Pro user, calling chart_tools.generate_and_save_chart (mocked)
            print("\n--- Test 5: Pro user, calling chart_tools.generate_and_save_chart ---")
            chart_code = """
import json
data = [{'date': '2023-01-01', 'value': 10}, {'date': '2023-01-02', 'value': 15}]
data_json = json.dumps(data)
# The `chart_tools` object is available in the exec_globals
chart_path = await chart_tools.generate_and_save_chart(
    data_json=data_json,
    chart_type='line',
    x_column='date',
    y_column='value',
    title='My Line Chart',
    user_context=user_context,
    library='matplotlib'
)
print(f"Chart generated at: {chart_path}")
"""
            result5 = await python_interpreter_with_rbac(chart_code, user_context=mock_user_pro_profile,
                                                         chart_tools=mock_chart_tools_instance, 
                                                         export_dataframe_to_file_func=mock_export_dataframe_to_file_func)
            print(f"Result 5 (Pro user, chart generation): {result5}")
            assert "Execution successful. Output:" in result5
            assert "Chart generated at: charts/mock_pro_token/mock_chart_" in result5
            # Verify a mock chart file was created
            chart_dir_for_pro = Path("charts") / mock_user_pro_profile.user_id
            assert any(f.name.startswith("mock_chart_") for f in chart_dir_for_pro.iterdir())
            print("Test 5 Passed.")

            # Test 6: Premium user, calling export_data_to_file (mocked)
            print("\n--- Test 6: Premium user, calling export_data_to_file ---")
            export_code = """
import json
data = [{'id': 1, 'name': 'Item A'}, {'id': 2, 'name': 'Item B'}]
data_json = json.dumps(data)
# The `export_data_to_file` function is available in the exec_globals
export_path = await export_data_to_file(
    data_json=data_json,
    user_context=user_context,
    file_prefix='my_analysis_data',
    export_format='csv'
)
print(f"Data exported to: {export_path}")
"""
            result6 = await python_interpreter_with_rbac(export_code, user_context=mock_user_premium_profile,
                                                         chart_tools=mock_chart_tools_instance, 
                                                         export_dataframe_to_file_func=mock_export_dataframe_to_file_func)
            print(f"Result 6 (Premium user, data export): {result6}")
            assert "Execution successful. Output:" in result6
            assert "Data exported to: exports/mock_premium_token/mock_data_" in result6
            # Verify a mock export file was created
            export_dir_for_premium = Path("exports") / mock_user_premium_profile.user_id
            assert any(f.name.startswith("mock_data_") for f in export_dir_for_premium.iterdir())
            print("Test 6 Passed.")

            print("\nAll PythonInterpreterTools tests completed.")

        # Run the async tests
        asyncio.run(run_interpreter_tests())

        # Clean up generated files and directories after all tests
        if Path("charts").exists():
            shutil.rmtree("charts")
            print(f"\nCleaned up charts directory: {Path('charts')}")
        if Path("exports").exists():
            shutil.rmtree("exports")
            print(f"Cleaned up exports directory: {Path('exports')}")
